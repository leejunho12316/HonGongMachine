{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNZjLDX98iTp3T3eb8WLIdC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leejunho12316/HonGongMachine/blob/main/%EB%B9%85%EB%B6%84%EA%B8%B0_Kaggle_Big_Data_Certificate_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#로지스틱 회귀 2단계"
      ],
      "metadata": {
        "id": "VOFjeuzJUtC9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "고객 정보를 나타낸 데이터이다. 주어진 데이터에서 500개 중 앞에서부터 350개는 train으로, 150개는 test 데이터로 나눈다. 모델을 학습(적합)할 때는 train 데이터를 사용하고, 예측할 때는 test 데이터를 사용한다. 모델은 로지스틱 회귀를 써서 고객이 특정 제품을 구매할지 여부를 예측하되, 페널티는 부과하지 않는다.\n",
        "\n",
        "종속변수: purchase (0: 구매 안 함, 1: 구매 함)\n",
        "\n",
        "1. 문제 1-1. income 변수를 독립변수로 purchase를 종속변수로 사용하여 로지스틱 회귀 모형을 만들고, income 변수가 한 단위 증가할 때 구매할 오즈비 값을 계산하시오. (반올림하여 소수 넷째자리까지 계산)\n",
        "\n",
        "2. 문제 1-2. 독립변수 income만 사용해 학습한 모델에서 test 데이터의 purchase를 예측하고, accuracy (정확도)를 구하시오. (반올림하여 소수 셋째자리까지 계산)\n",
        "\n",
        "3. 문제 1-3. 독립변수 income만 사용해 학습한 모델의 로짓 우도를 계산하시오.\n",
        "\n",
        "4. 문제 1-4. 독립변수 income만 사용해 학습한 모델의 유의확률(p-value)를 구하시오."
      ],
      "metadata": {
        "id": "BTl6qR1QU4N2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from statsmodels.formula.api import logit\n",
        "import statsmodels.api as sm\n",
        "import numpy as np\n",
        "df = pd.read_csv('Customer_Data.csv')\n",
        "train = df.iloc[:350]\n",
        "test = df.iloc[350:]\n",
        "\n",
        "#문제1-1\n",
        "model = logit('purchase~income', data=train).fit()\n",
        "res = np.exp(model.params['income'])\n",
        "print(res)\n",
        "\n",
        "#문제1-2.\n",
        "test['predict'] = model.predict(test)\n",
        "test['predict'] = test['predict'] > 0.5\n",
        "acc = (test['purchase'] == test['predict']).sum() / len(test)\n",
        "print(round(acc, 3))\n",
        "\n",
        "#문제 1-3. 독립변수 income만 사용해 학습한 모델의 로짓 우도를 계산하시오.\n",
        "print(model.llf)\n",
        "\n",
        "#문제 1-4. 독립변수 income만 사용해 학습한 모델의 유의확률(p-value)를 구하시오.\n",
        "print(model.pvalues['income'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c-7Bi_SU7UL",
        "outputId": "79f8e2f1-39ff-4f86-86a6-aceb7ba6a34f"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimization terminated successfully.\n",
            "         Current function value: 0.692599\n",
            "         Iterations 3\n",
            "1.0000019601805765\n",
            "0.507\n",
            "-242.40981957168498\n",
            "0.5964910811075119\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1328321396.py:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test['predict'] = model.predict(test)\n",
            "/tmp/ipython-input-1328321396.py:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test['predict'] = test['predict'] > 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(test['purchase'] == test['predict']).sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOPX6s1yasvO",
        "outputId": "f784a609-ca61-48b3-918f-ca7881ed7b22"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.int64(76)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MeIbwocGaLge",
        "outputId": "4fbf952b-3ffe-4406-b646-b939a6557561"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(1.0000019601805765)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "format(model.params['income'], '.10f')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Z_VydhxVZWdY",
        "outputId": "cc1455c8-4395-4ec2-a801-19d8c1a06f9d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.0000026642'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#잔차이탈도"
      ],
      "metadata": {
        "id": "mA0ycJ03btV7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "잔차이탈도를 구하시오\n",
        "고객 정보를 나타낸 데이터이다. 주어진 데이터에서 500개 중 앞에서부터 300개는 train으로, 200개는 test 데이터로 나눈다. 모델을 학습(적합)할 때는 train 데이터를 사용하고, 예측할 때는 test 데이터를 사용한다. 모델은 로지스틱 회귀를 써서 고객이 특정 제품을 구매할지 여부를 예측하되, 페널티는 부과하지 않는다.\n",
        "\n",
        "종속변수: purchase (0: 구매 안 함, 1: 구매 함)\n",
        "\n",
        "Q. age, income, marital_status 변수를 독립변수로 purchase를 종속변수로 사용하여 로지스틱 회귀 모형을 만들고, 잔차이탈도를 구하시오. (반올림하여 소수 넷째자리까지 계산)"
      ],
      "metadata": {
        "id": "muUBFXvibwLq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('Customer_Data.csv')\n",
        "train = df.iloc[:300]\n",
        "test = df.iloc[300:]\n",
        "\n",
        "from statsmodels.formula.api import logit\n",
        "model = logit('purchase~age+income+marital_status', data=train).fit()\n",
        "print(round(model.llf * -2, 4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epieqn0Bb2G_",
        "outputId": "50198ec9-b2b4-48e2-afc4-ebc2fc2fdded"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimization terminated successfully.\n",
            "         Current function value: 0.687415\n",
            "         Iterations 4\n",
            "412.449\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#AIC/BIC"
      ],
      "metadata": {
        "id": "y4lMJoAecUtS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "로지스틱 회귀 모델의 AIC와 BIC 계산¶\n",
        "독립변수(Pregnancies, BMI, DiabetesPedigreeFunction)를 사용하여 로지스틱 회귀 모델을 학습하고, 학습된 모델의 AIC와 BIC 값을 계산하세요.(종속변수는 Outcome)\n",
        "\n",
        "문제1\n",
        "모델의 로그 우도(Log-Likelihood)를 기반으로 AIC와 BIC 값을 계산하세요."
      ],
      "metadata": {
        "id": "oLCUr4uSfMd_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('diabetes_train.csv')\n",
        "\n",
        "from statsmodels.formula.api import logit\n",
        "import statsmodels.api as sm\n",
        "model = logit('Outcome~Pregnancies+BMI+DiabetesPedigreeFunction', data=df).fit()\n",
        "model.aic, model.bic"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAPHRAhIfQsp",
        "outputId": "0daa0edb-9aa1-4dc9-d18a-9da7bba5893f"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimization terminated successfully.\n",
            "         Current function value: 0.549382\n",
            "         Iterations 6\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(np.float64(640.8879324373285), np.float64(658.312363080112))"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "문제2\n",
        "Pregnancies를 범주형 변수로 처리하여 로지스틱 회귀 모델을 학습하세요. (독립변수(Pregnancies, BMI, DiabetesPedigreeFunction)를 사용)\n",
        "모델의 로그 우도(Log-Likelihood)를 구하"
      ],
      "metadata": {
        "id": "wv0Vg9acfaa8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = logit('Outcome~C(Pregnancies)+BMI+DiabetesPedigreeFunction', data=df).fit()\n",
        "print(model.llf)\n",
        "print(model.aic, model.bic)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9HT6G5rg1Ck",
        "outputId": "a79c6e06-1b5d-4c0f-8be9-49b24be63c66"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Maximum number of iterations has been exceeded.\n",
            "         Current function value: 0.528387\n",
            "         Iterations: 35\n",
            "-304.3508403850429\n",
            "646.7016807700858 729.4677263233077\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#다중 선형회귀"
      ],
      "metadata": {
        "id": "NPAcmHLqhPvf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv(\"t3_regression_data.csv\")\n",
        "\n",
        "#1. 모든 변수를 사용하여 OLS 모델을 적합하고, 회귀계수 중 가장 큰 값은?\n",
        "from statsmodels.formula.api import ols\n",
        "model = ols('y~x1+x2+x3+x4', data=data).fit()\n",
        "print('1. intercept 포함시 2.9816, 미포함시 1.9979')\n",
        "\n",
        "#2. 유의미하지 않은 변수를 제거한 후 모델을 다시 적합하고, 회귀계수 중 가장 작은 변수명은?\n",
        "model = ols('y~x1+x2+x3', data=data).fit()\n",
        "print('2. 회귀계수가 가장 작은 변수명 : x2')\n",
        "\n",
        "#3. 2번 모델의 R-squared 값을 계산하고 해석하세요.\n",
        "print('3. ', model.rsquared, ': 전체 데이터 중 모델이 설명하는 비율 (R2 score = SSR/SST)')\n",
        "\n",
        "#4. 1번 모델에서 새로운 데이터(x1=5, x2=12, x3=10, x4=3)에 대해 y 값을 예측하세요.\n",
        "model = ols('y~x1+x2+x3+x4', data=data).fit()\n",
        "new_data = pd.DataFrame({\n",
        "    'x1' : [5], 'x2' : [12], 'x3' : [10], 'x4' : [3]\n",
        "})\n",
        "print('4. ',model.predict(new_data)[0])\n",
        "\n",
        "#5. 1번 모델에서 x1, x2, x3, x4의 상관관계를 계산하고 가장 큰 상관계수를 구하시오. (단, 자기 상관관계 제외)\n",
        "data[['x1','x2','x3','x4']].corr()\n",
        "print('5. : 0.117670')\n",
        "\n",
        "#6. x1과 x2만을 예측 변수로 사용하는 모델을 적합하고, 전체 모델과 R-squared 값을 구하시오.\n",
        "model = ols('y~x1+x2', data=data).fit()\n",
        "print('6. ', model.rsquared)\n",
        "\n",
        "#7. 잔차(residual) 분석을 수행하고, 잔차의 표준편차를 구하시오.\n",
        "#여기부터 모름"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "id": "OwBo0uPrhQjS",
        "outputId": "9b093029-b7c5-48f5-e24e-53453b5c5616"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. intercept 포함시 2.9816, 미포함시 1.9979\n",
            "2. 회귀계수가 가장 작은 변수명 : x2\n",
            "3.  0.9881643592045125 : 전체 데이터 중 모델이 설명하는 비율 (R2 score = SSR/SST)\n",
            "4.  -0.2433084582017353\n",
            "5. : 0.117670\n",
            "6.  0.9642665748957848\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                            OLS Regression Results                            \n",
              "==============================================================================\n",
              "Dep. Variable:                      y   R-squared:                       0.964\n",
              "Model:                            OLS   Adj. R-squared:                  0.964\n",
              "Method:                 Least Squares   F-statistic:                     1309.\n",
              "Date:                Sun, 09 Nov 2025   Prob (F-statistic):           6.67e-71\n",
              "Time:                        12:18:54   Log-Likelihood:                -186.16\n",
              "No. Observations:                 100   AIC:                             378.3\n",
              "Df Residuals:                      97   BIC:                             386.1\n",
              "Df Model:                           2                                         \n",
              "Covariance Type:            nonrobust                                         \n",
              "==============================================================================\n",
              "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
              "------------------------------------------------------------------------------\n",
              "Intercept      8.7356      0.914      9.559      0.000       6.922      10.549\n",
              "x1             2.0247      0.051     39.356      0.000       1.923       2.127\n",
              "x2            -1.5656      0.056    -27.941      0.000      -1.677      -1.454\n",
              "==============================================================================\n",
              "Omnibus:                       10.929   Durbin-Watson:                   1.966\n",
              "Prob(Omnibus):                  0.004   Jarque-Bera (JB):                3.939\n",
              "Skew:                           0.132   Prob(JB):                        0.140\n",
              "Kurtosis:                       2.064   Cond. No.                         92.5\n",
              "==============================================================================\n",
              "\n",
              "Notes:\n",
              "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
              "\"\"\""
            ],
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>OLS Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.964</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.964</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   1309.</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Sun, 09 Nov 2025</td> <th>  Prob (F-statistic):</th> <td>6.67e-71</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>12:18:54</td>     <th>  Log-Likelihood:    </th> <td> -186.16</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>      <td>   100</td>      <th>  AIC:               </th> <td>   378.3</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Residuals:</th>          <td>    97</td>      <th>  BIC:               </th> <td>   386.1</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Intercept</th> <td>    8.7356</td> <td>    0.914</td> <td>    9.559</td> <td> 0.000</td> <td>    6.922</td> <td>   10.549</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x1</th>        <td>    2.0247</td> <td>    0.051</td> <td>   39.356</td> <td> 0.000</td> <td>    1.923</td> <td>    2.127</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x2</th>        <td>   -1.5656</td> <td>    0.056</td> <td>  -27.941</td> <td> 0.000</td> <td>   -1.677</td> <td>   -1.454</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "  <th>Omnibus:</th>       <td>10.929</td> <th>  Durbin-Watson:     </th> <td>   1.966</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(Omnibus):</th> <td> 0.004</td> <th>  Jarque-Bera (JB):  </th> <td>   3.939</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Skew:</th>          <td> 0.132</td> <th>  Prob(JB):          </th> <td>   0.140</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Kurtosis:</th>      <td> 2.064</td> <th>  Cond. No.          </th> <td>    92.5</td>\n",
              "</tr>\n",
              "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
            ],
            "text/latex": "\\begin{center}\n\\begin{tabular}{lclc}\n\\toprule\n\\textbf{Dep. Variable:}    &        y         & \\textbf{  R-squared:         } &     0.964   \\\\\n\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.964   \\\\\n\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     1309.   \\\\\n\\textbf{Date:}             & Sun, 09 Nov 2025 & \\textbf{  Prob (F-statistic):} &  6.67e-71   \\\\\n\\textbf{Time:}             &     12:18:54     & \\textbf{  Log-Likelihood:    } &   -186.16   \\\\\n\\textbf{No. Observations:} &         100      & \\textbf{  AIC:               } &     378.3   \\\\\n\\textbf{Df Residuals:}     &          97      & \\textbf{  BIC:               } &     386.1   \\\\\n\\textbf{Df Model:}         &           2      & \\textbf{                     } &             \\\\\n\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n\\bottomrule\n\\end{tabular}\n\\begin{tabular}{lcccccc}\n                   & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n\\midrule\n\\textbf{Intercept} &       8.7356  &        0.914     &     9.559  &         0.000        &        6.922    &       10.549     \\\\\n\\textbf{x1}        &       2.0247  &        0.051     &    39.356  &         0.000        &        1.923    &        2.127     \\\\\n\\textbf{x2}        &      -1.5656  &        0.056     &   -27.941  &         0.000        &       -1.677    &       -1.454     \\\\\n\\bottomrule\n\\end{tabular}\n\\begin{tabular}{lclc}\n\\textbf{Omnibus:}       & 10.929 & \\textbf{  Durbin-Watson:     } &    1.966  \\\\\n\\textbf{Prob(Omnibus):} &  0.004 & \\textbf{  Jarque-Bera (JB):  } &    3.939  \\\\\n\\textbf{Skew:}          &  0.132 & \\textbf{  Prob(JB):          } &    0.140  \\\\\n\\textbf{Kurtosis:}      &  2.064 & \\textbf{  Cond. No.          } &     92.5  \\\\\n\\bottomrule\n\\end{tabular}\n%\\caption{OLS Regression Results}\n\\end{center}\n\nNotes: \\newline\n [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#비모수검정 (Wilcoxon)"
      ],
      "metadata": {
        "id": "HMq23ZEJkjAN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "베스킨라빈스는 쿼트(Quart) 아이스크림의 중앙값이 620g이라고 주장하고 있습니다. 저는 실제로 이 아이스크림의 중앙값이 620g보다 무겁다고 주장합니다. 다음은 20개의 쿼트 아이스크림 샘플의 무게 측정 결과입니다. 이 측정 결과를 바탕으로 나의 주장이 사실인지 비모수 검정(Wilcoxon Signed-Rank Test)을 통해 검정해보십시오. p-value값을 반올림하여 소수점 둘째 자리까지 계산\n",
        "\n",
        "- 귀무가설: \"베스킨라빈스 쿼트 아이스크림의 중앙값은 620g이다.\"\n",
        "- 대립가설: \"베스킨라빈스 쿼트 아이스크림의 중앙값은 620g보다 무겁다.\"\n"
      ],
      "metadata": {
        "id": "bIE-NYrEkliY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data = {\n",
        "    \"weight\": [630, 610, 625, 615, 622, 618, 623, 619, 620, 624, 616, 621, 617, 629, 626, 620, 618, 622, 625, 615,\n",
        "               628, 617, 624, 619, 621, 623, 620, 622, 618, 625, 616, 629, 620, 624, 617, 621, 623, 619, 625, 618,\n",
        "               622, 620, 624, 617, 621, 623, 619, 625, 618, 622]\n",
        "}\n",
        "df = pd.DataFrame(data)"
      ],
      "metadata": {
        "id": "HtyG5jRmkvOy"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "\n",
        "s,p = stats.wilcoxon(df['weight']-620, alternative = 'greater')\n",
        "s,p = stats.wilcoxon(df['weight'], 620, alternative = 'greater')\n",
        "print(round(p,2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3_P41TPkxb0",
        "outputId": "b26b1a60-9a57-4cc3-fde1-036904b1e0b3"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.03\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "help(stats.wilcoxon)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMTHKHt2lIvO",
        "outputId": "8c344a9c-5217-427e-82ed-bbf9cf199efb"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on function wilcoxon in module scipy.stats._morestats:\n",
            "\n",
            "wilcoxon(x, y=None, zero_method='wilcox', correction=False, alternative='two-sided', method='auto', *, axis=0, nan_policy='propagate', keepdims=False)\n",
            "    Calculate the Wilcoxon signed-rank test.\n",
            "\n",
            "    The Wilcoxon signed-rank test tests the null hypothesis that two\n",
            "    related paired samples come from the same distribution. In particular,\n",
            "    it tests whether the distribution of the differences ``x - y`` is symmetric\n",
            "    about zero. It is a non-parametric version of the paired T-test.\n",
            "\n",
            "    Parameters\n",
            "    ----------\n",
            "    x : array_like\n",
            "        Either the first set of measurements (in which case ``y`` is the second\n",
            "        set of measurements), or the differences between two sets of\n",
            "        measurements (in which case ``y`` is not to be specified.)  Must be\n",
            "        one-dimensional.\n",
            "    y : array_like, optional\n",
            "        Either the second set of measurements (if ``x`` is the first set of\n",
            "        measurements), or not specified (if ``x`` is the differences between\n",
            "        two sets of measurements.)  Must be one-dimensional.\n",
            "\n",
            "        .. warning::\n",
            "            When `y` is provided, `wilcoxon` calculates the test statistic\n",
            "            based on the ranks of the absolute values of ``d = x - y``.\n",
            "            Roundoff error in the subtraction can result in elements of ``d``\n",
            "            being assigned different ranks even when they would be tied with\n",
            "            exact arithmetic. Rather than passing `x` and `y` separately,\n",
            "            consider computing the difference ``x - y``, rounding as needed to\n",
            "            ensure that only truly unique elements are numerically distinct,\n",
            "            and passing the result as `x`, leaving `y` at the default (None).\n",
            "    zero_method : {\"wilcox\", \"pratt\", \"zsplit\"}, optional\n",
            "        There are different conventions for handling pairs of observations\n",
            "        with equal values (\"zero-differences\", or \"zeros\").\n",
            "\n",
            "        * \"wilcox\": Discards all zero-differences (default); see [4]_.\n",
            "        * \"pratt\": Includes zero-differences in the ranking process,\n",
            "          but drops the ranks of the zeros (more conservative); see [3]_.\n",
            "          In this case, the normal approximation is adjusted as in [5]_.\n",
            "        * \"zsplit\": Includes zero-differences in the ranking process and\n",
            "          splits the zero rank between positive and negative ones.\n",
            "    correction : bool, optional\n",
            "        If True, apply continuity correction by adjusting the Wilcoxon rank\n",
            "        statistic by 0.5 towards the mean value when computing the\n",
            "        z-statistic if a normal approximation is used.  Default is False.\n",
            "    alternative : {\"two-sided\", \"greater\", \"less\"}, optional\n",
            "        Defines the alternative hypothesis. Default is 'two-sided'.\n",
            "        In the following, let ``d`` represent the difference between the paired\n",
            "        samples: ``d = x - y`` if both ``x`` and ``y`` are provided, or\n",
            "        ``d = x`` otherwise.\n",
            "\n",
            "        * 'two-sided': the distribution underlying ``d`` is not symmetric\n",
            "          about zero.\n",
            "        * 'less': the distribution underlying ``d`` is stochastically less\n",
            "          than a distribution symmetric about zero.\n",
            "        * 'greater': the distribution underlying ``d`` is stochastically\n",
            "          greater than a distribution symmetric about zero.\n",
            "    method : {\"auto\", \"exact\", \"asymptotic\"} or `PermutationMethod` instance, optional\n",
            "        Method to calculate the p-value, see Notes. Default is \"auto\".\n",
            "    axis : int or None, default: 0\n",
            "        If an int, the axis of the input along which to compute the statistic.\n",
            "        The statistic of each axis-slice (e.g. row) of the input will appear in a\n",
            "        corresponding element of the output.\n",
            "        If ``None``, the input will be raveled before computing the statistic.\n",
            "    nan_policy : {'propagate', 'omit', 'raise'}\n",
            "        Defines how to handle input NaNs.\n",
            "\n",
            "        - ``propagate``: if a NaN is present in the axis slice (e.g. row) along\n",
            "          which the  statistic is computed, the corresponding entry of the output\n",
            "          will be NaN.\n",
            "        - ``omit``: NaNs will be omitted when performing the calculation.\n",
            "          If insufficient data remains in the axis slice along which the\n",
            "          statistic is computed, the corresponding entry of the output will be\n",
            "          NaN.\n",
            "        - ``raise``: if a NaN is present, a ``ValueError`` will be raised.\n",
            "    keepdims : bool, default: False\n",
            "        If this is set to True, the axes which are reduced are left\n",
            "        in the result as dimensions with size one. With this option,\n",
            "        the result will broadcast correctly against the input array.\n",
            "\n",
            "    Returns\n",
            "    -------\n",
            "    An object with the following attributes.\n",
            "    statistic : array_like\n",
            "        If `alternative` is \"two-sided\", the sum of the ranks of the\n",
            "        differences above or below zero, whichever is smaller.\n",
            "        Otherwise the sum of the ranks of the differences above zero.\n",
            "    pvalue : array_like\n",
            "        The p-value for the test depending on `alternative` and `method`.\n",
            "    zstatistic : array_like\n",
            "        When ``method = 'asymptotic'``, this is the normalized z-statistic::\n",
            "\n",
            "            z = (T - mn - d) / se\n",
            "\n",
            "        where ``T`` is `statistic` as defined above, ``mn`` is the mean of the\n",
            "        distribution under the null hypothesis, ``d`` is a continuity\n",
            "        correction, and ``se`` is the standard error.\n",
            "        When ``method != 'asymptotic'``, this attribute is not available.\n",
            "\n",
            "    See Also\n",
            "    --------\n",
            "\n",
            "    :func:`kruskal`, :func:`mannwhitneyu`\n",
            "        ..\n",
            "\n",
            "    Notes\n",
            "    -----\n",
            "    In the following, let ``d`` represent the difference between the paired\n",
            "    samples: ``d = x - y`` if both ``x`` and ``y`` are provided, or ``d = x``\n",
            "    otherwise. Assume that all elements of ``d`` are independent and\n",
            "    identically distributed observations, and all are distinct and nonzero.\n",
            "\n",
            "    - When ``len(d)`` is sufficiently large, the null distribution of the\n",
            "      normalized test statistic (`zstatistic` above) is approximately normal,\n",
            "      and ``method = 'asymptotic'`` can be used to compute the p-value.\n",
            "\n",
            "    - When ``len(d)`` is small, the normal approximation may not be accurate,\n",
            "      and ``method='exact'`` is preferred (at the cost of additional\n",
            "      execution time).\n",
            "\n",
            "    - The default, ``method='auto'``, selects between the two:\n",
            "      ``method='exact'`` is used when ``len(d) <= 50``, and\n",
            "      ``method='asymptotic'`` is used otherwise.\n",
            "\n",
            "    The presence of \"ties\" (i.e. not all elements of ``d`` are unique) or\n",
            "    \"zeros\" (i.e. elements of ``d`` are zero) changes the null distribution\n",
            "    of the test statistic, and ``method='exact'`` no longer calculates\n",
            "    the exact p-value. If ``method='asymptotic'``, the z-statistic is adjusted\n",
            "    for more accurate comparison against the standard normal, but still,\n",
            "    for finite sample sizes, the standard normal is only an approximation of\n",
            "    the true null distribution of the z-statistic. For such situations, the\n",
            "    `method` parameter also accepts instances of `PermutationMethod`. In this\n",
            "    case, the p-value is computed using `permutation_test` with the provided\n",
            "    configuration options and other appropriate settings.\n",
            "\n",
            "    The presence of ties and zeros affects the resolution of ``method='auto'``\n",
            "    accordingly: exhasutive permutations are performed when ``len(d) <= 13``,\n",
            "    and the asymptotic method is used otherwise. Note that they asymptotic\n",
            "    method may not be very accurate even for ``len(d) > 14``; the threshold\n",
            "    was chosen as a compromise between execution time and accuracy under the\n",
            "    constraint that the results must be deterministic. Consider providing an\n",
            "    instance of `PermutationMethod` method manually, choosing the\n",
            "    ``n_resamples`` parameter to balance time constraints and accuracy\n",
            "    requirements.\n",
            "\n",
            "    Please also note that in the edge case that all elements of ``d`` are zero,\n",
            "    the p-value relying on the normal approximaton cannot be computed (NaN)\n",
            "    if ``zero_method='wilcox'`` or ``zero_method='pratt'``.\n",
            "\n",
            "    Beginning in SciPy 1.9, ``np.matrix`` inputs (not recommended for new\n",
            "    code) are converted to ``np.ndarray`` before the calculation is performed. In\n",
            "    this case, the output will be a scalar or ``np.ndarray`` of appropriate shape\n",
            "    rather than a 2D ``np.matrix``. Similarly, while masked elements of masked\n",
            "    arrays are ignored, the output will be a scalar or ``np.ndarray`` rather than a\n",
            "    masked array with ``mask=False``.\n",
            "\n",
            "    References\n",
            "    ----------\n",
            "    .. [1] https://en.wikipedia.org/wiki/Wilcoxon_signed-rank_test\n",
            "    .. [2] Conover, W.J., Practical Nonparametric Statistics, 1971.\n",
            "    .. [3] Pratt, J.W., Remarks on Zeros and Ties in the Wilcoxon Signed\n",
            "       Rank Procedures, Journal of the American Statistical Association,\n",
            "       Vol. 54, 1959, pp. 655-667. :doi:`10.1080/01621459.1959.10501526`\n",
            "    .. [4] Wilcoxon, F., Individual Comparisons by Ranking Methods,\n",
            "       Biometrics Bulletin, Vol. 1, 1945, pp. 80-83. :doi:`10.2307/3001968`\n",
            "    .. [5] Cureton, E.E., The Normal Approximation to the Signed-Rank\n",
            "       Sampling Distribution When Zero Differences are Present,\n",
            "       Journal of the American Statistical Association, Vol. 62, 1967,\n",
            "       pp. 1068-1069. :doi:`10.1080/01621459.1967.10500917`\n",
            "\n",
            "    Examples\n",
            "    --------\n",
            "    In [4]_, the differences in height between cross- and self-fertilized\n",
            "    corn plants is given as follows:\n",
            "\n",
            "    >>> d = [6, 8, 14, 16, 23, 24, 28, 29, 41, -48, 49, 56, 60, -67, 75]\n",
            "\n",
            "    Cross-fertilized plants appear to be higher. To test the null\n",
            "    hypothesis that there is no height difference, we can apply the\n",
            "    two-sided test:\n",
            "\n",
            "    >>> from scipy.stats import wilcoxon\n",
            "    >>> res = wilcoxon(d)\n",
            "    >>> res.statistic, res.pvalue\n",
            "    (24.0, 0.041259765625)\n",
            "\n",
            "    Hence, we would reject the null hypothesis at a confidence level of 5%,\n",
            "    concluding that there is a difference in height between the groups.\n",
            "    To confirm that the median of the differences can be assumed to be\n",
            "    positive, we use:\n",
            "\n",
            "    >>> res = wilcoxon(d, alternative='greater')\n",
            "    >>> res.statistic, res.pvalue\n",
            "    (96.0, 0.0206298828125)\n",
            "\n",
            "    This shows that the null hypothesis that the median is negative can be\n",
            "    rejected at a confidence level of 5% in favor of the alternative that\n",
            "    the median is greater than zero. The p-values above are exact. Using the\n",
            "    normal approximation gives very similar values:\n",
            "\n",
            "    >>> res = wilcoxon(d, method='asymptotic')\n",
            "    >>> res.statistic, res.pvalue\n",
            "    (24.0, 0.04088813291185591)\n",
            "\n",
            "    Note that the statistic changed to 96 in the one-sided case (the sum\n",
            "    of ranks of positive differences) whereas it is 24 in the two-sided\n",
            "    case (the minimum of sum of ranks above and below zero).\n",
            "\n",
            "    In the example above, the differences in height between paired plants are\n",
            "    provided to `wilcoxon` directly. Alternatively, `wilcoxon` accepts two\n",
            "    samples of equal length, calculates the differences between paired\n",
            "    elements, then performs the test. Consider the samples ``x`` and ``y``:\n",
            "\n",
            "    >>> import numpy as np\n",
            "    >>> x = np.array([0.5, 0.825, 0.375, 0.5])\n",
            "    >>> y = np.array([0.525, 0.775, 0.325, 0.55])\n",
            "    >>> res = wilcoxon(x, y, alternative='greater')\n",
            "    >>> res\n",
            "    WilcoxonResult(statistic=5.0, pvalue=0.5625)\n",
            "\n",
            "    Note that had we calculated the differences by hand, the test would have\n",
            "    produced different results:\n",
            "\n",
            "    >>> d = [-0.025, 0.05, 0.05, -0.05]\n",
            "    >>> ref = wilcoxon(d, alternative='greater')\n",
            "    >>> ref\n",
            "    WilcoxonResult(statistic=6.0, pvalue=0.5)\n",
            "\n",
            "    The substantial difference is due to roundoff error in the results of\n",
            "    ``x-y``:\n",
            "\n",
            "    >>> d - (x-y)\n",
            "    array([2.08166817e-17, 6.93889390e-17, 1.38777878e-17, 4.16333634e-17])\n",
            "\n",
            "    Even though we expected all the elements of ``(x-y)[1:]`` to have the same\n",
            "    magnitude ``0.05``, they have slightly different magnitudes in practice,\n",
            "    and therefore are assigned different ranks in the test. Before performing\n",
            "    the test, consider calculating ``d`` and adjusting it as necessary to\n",
            "    ensure that theoretically identically values are not numerically distinct.\n",
            "    For example:\n",
            "\n",
            "    >>> d2 = np.around(x - y, decimals=3)\n",
            "    >>> wilcoxon(d2, alternative='greater')\n",
            "    WilcoxonResult(statistic=6.0, pvalue=0.5)\n",
            "\n"
          ]
        }
      ]
    }
  ]
}